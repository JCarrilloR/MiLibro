# Analisis metatranscriptomicos (RNA-seq)

Descripci√≥n del cap√≠tulo

## Descragando secuencias crudas de un bioproject. Para recuperar las secuencias crudas asociadas al BioProject PRJNA935796, se utiliz√≥ el paquete EDirect en combinaci√≥n con el SRA Toolkit. En primer lugar, se consult√≥ la base de datos SRA mediante el comando esearch, recuperando la tabla de metadatos en formato runinfo con efetch, la cual fue almacenada en un archivo (runinfo.csv). A partir de este archivo se extrajo la columna Run, que contiene los identificadores √∫nicos de cada corrida de secuenciaci√≥n (SRR), generando as√≠ una lista (SRR_list.txt). Finalmente, cada uno de los accesos SRR fue descargado de manera iterativa mediante el comando fasterq-dump, utilizando ocho hilos en paralelo (-e 8) y guardando las lecturas crudas en la carpeta raw_sequences.

# Obtener lista de SRR
esearch -db sra -query PRJNA935796 | efetch -format runinfo > runinfo.csv

# Extraer la columna "Run" (SRR IDs)
cut -d',' -f1 runinfo.csv | grep SRR > SRR_list.txt

# Descargar todas las muestras
for srr in $(cat SRR_list.txt); do
  fasterq-dump $srr -O ./raw_sequences -e 12
done




## Analisis de calidad inicial. Se realiz√≥ un an√°lisis de control de calidad con FastQC sobre todas las lecturas crudas en formato FASTQ, considerando archivos comprimidos y no comprimidos correspondientes a lecturas forward y reverse. Los reportes se generaron en paralelo utilizando ocho hilos de procesamiento y se almacenaron en la carpeta fastqc_raw, que contiene tanto los archivos HTML para la inspecci√≥n visual de la calidad como los archivos comprimidos con los datos num√©ricos de cada muestra.

gunzip *.gz

#!/bin/zsh

set -e                    # Detener el script si ocurre un error
setopt NULL_GLOB          # Si no hay coincidencias, los patrones se expanden a vac√≠o

outdir="fastqc_raw"       # Carpeta de salida para los resultados
mkdir -p "$outdir"        # Crear la carpeta si no existe

# Buscar archivos FASTQ crudos (acepta .fastq y .fastq.gz)
typeset -a RAW_FILES
RAW_FILES=( *_R1_001.fastq *_R2_001.fastq *_R1_001.fastq.gz *_R2_001.fastq.gz )

# Verificar que existan archivos
(( ${#RAW_FILES} > 0 )) || { echo "No se encontraron archivos FASTQ crudos en el directorio actual."; exit 1; }

# Ejecutar FastQC con 8 hilos sobre todos los archivos encontrados
fastqc -t 8 -o "$outdir" $RAW_FILES

echo "‚úÖ An√°lisis de FastQC completado. Resultados guardados en: $PWD/$outdir"


#Se integraron los reportes individuales de FastQC correspondientes a las lecturas crudas mediante MultiQC, generando un informe consolidado en formato HTML con las principales m√©tricas de calidad. Asimismo, el archivo tabular multiqc_general_stats.txt, que resume los valores num√©ricos de todas las muestras, fue copiado al directorio ra√≠z del proyecto para facilitar su comparaci√≥n y an√°lisis posterior.


desde aqui version 2


#!/bin/zsh

# Script para integrar reportes FASTQC con MultiQC
# Genera un HTML consolidado y copia multiqc_general_stats.txt al directorio ra√≠z

set -euo pipefail  # -e: salir si hay error; -u: error en variables no definidas; -o pipefail: propaga errores en pipelines

indir="fastqc_raw"                  # Carpeta donde est√°n los resultados de FastQC
outdir="fastqc_raw/multiqc_data"    # Carpeta donde MultiQC guardar√° resultados

# Crea la carpeta de salida si no existe
mkdir -p "$outdir"

# Verifica que existan reportes de FastQC (*.zip)
ls "$indir"/*fastqc.zip >/dev/null 2>&1 || { 
  echo "‚ö†Ô∏è  No se encontraron resultados de FastQC en $indir (no hay *fastqc.zip)"; 
  exit 1; 
}

# Ejecuta MultiQC sobre fastqc_raw
multiqc "$indir" \
  --outdir "$outdir" \
  --filename multiqc_fastqc_raw

# Copia el archivo de estad√≠sticas generales al directorio ra√≠z
cp "$outdir"/multiqc_fastqc_raw_data/multiqc_general_stats.txt ./multiqc_general_stats.txt


# Limpieza de secuencias
# Raw paired-end RNA-seq reads were processed with Cutadapt (vX.X) to remove adapter contamination and low-quality bases. TruSeq Illumina adapter sequences were trimmed from both read ends, and poly-A tails of ‚â•10 nucleotides were clipped when present. Quality trimming was applied with a Phred threshold of 20 at both 5‚Ä≤ and 3‚Ä≤ ends, and reads shorter than 20 nucleotides after trimming were discarded. Filtering also removed reads containing ambiguous bases (N). Processing was performed in parallel across all samples, and per-sample reports were generated and subsequently summarized with MultiQC.

# Las lecturas crudas pareadas de RNA-seq se procesaron con Cutadapt (vX.X) para eliminar la contaminaci√≥n por adaptadores y las bases de baja calidad. Las secuencias de adaptadores TruSeq de Illumina se recortaron en ambos extremos de las lecturas y, cuando estuvieron presentes, se eliminaron colas poli-A de ‚â•10 nucle√≥tidos. Se aplic√≥ un recorte por calidad con un umbral Phred de 20 en los extremos 5‚Ä≤ y 3‚Ä≤, y las lecturas con una longitud final menor a 20 nucle√≥tidos se descartaron. Asimismo, se filtraron las lecturas que conten√≠an bases ambiguas (N). El procesamiento se realiz√≥ en paralelo para todas las muestras y se generaron reportes individuales, que posteriormente fueron resumidos con MultiQC.


#!/bin/zsh

set -e                    # Salir si alg√∫n comando falla
setopt NULL_GLOB         # En zsh: patrones sin match se expanden a ‚Äúnada‚Äù (no quedan literales)

outdir="cutadapt_results"
mkdir -p "$outdir"

# Construye la lista de archivos R1 v√°lidos (acepta .fastq y .fastq.gz)
typeset -a R1_FILES
R1_FILES=( *_R1_001.fastq *_R1_001.fastq.gz )

# Si no hay archivos que coincidan, termina con mensaje claro
if (( ${#R1_FILES} == 0 )); then
  echo "No se encontraron archivos que coincidan con *_R1_001.fastq(.gz) en el directorio actual."
  exit 1
fi

# Recorre cada R1 y empareja su R2 correspondiente
for R1 in $R1_FILES; do
  if [[ "$R1" == *.fastq.gz ]]; then
    base="${R1%_R1_001.fastq.gz}"          # nombre sin sufijo
    R2="${base}_R2_001.fastq.gz"           # par esperado
    ext=".fastq.gz"                        # extensi√≥n de salida
  else
    base="${R1%_R1_001.fastq}"
    R2="${base}_R2_001.fastq"
    ext=".fastq"
  fi

  # Verifica que exista el par R2
  if [[ ! -f "$R2" ]]; then
    echo "‚ö†Ô∏è  No se encontr√≥ el par R2 para: $R1   (esperado: $R2). Se omite."
    continue
  fi

  echo "Procesando: R1=$R1   R2=$R2"

  # Ejecuta cutadapt en UNA sola l√≠nea (evita problemas al pegar en zsh)
  cutadapt -j 8 -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCA -A AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT -a A{10} -A A{10} -q 30,30 -m 20 --max-n 0 --overlap 5 -e 0.1 --trim-n --pair-filter=any --json "${outdir}/${base:t}.cutadapt.json" --report=minimal -o "${outdir}/${base:t}_R1.trimmed${ext}" -p "${outdir}/${base:t}_R2.trimmed${ext}" "$R1" "$R2"
done

echo "An√°lisis completado. Resultados guardados en: ${outdir}/"


##Notas (l√≠nea por l√≠nea)
##!/bin/zsh ‚Üí fuerza a ejecutar con zsh (aunque tu shell por defecto sea otro).
##set -e ‚Üí si algo falla, el script se detiene (evitas resultados a medias).
##setopt NULL_GLOB ‚Üí en zsh, si el patr√≥n no coincide, se expande a vac√≠o (no deja literales como *_R1_001.fastq).
##outdir="cutadapt_results" y mkdir -p "$outdir" ‚Üí define y crea la carpeta de salida.
##R1_FILES=( *_R1_001.fastq *_R1_001.fastq.gz ) ‚Üí arma la lista de archivos R1 v√°lidos, aceptando ambos formatos.
##if (( ${#R1_FILES} == 0 )), fi es simplemente el cierre de una estructura if‚Üí si la lista est√° vac√≠a, termina con un mensaje claro.
##Bloque if [[ "$R1" == *.fastq.gz ]] ‚Üí detecta si la muestra es comprimida o no y ajusta sufijos/extensiones.
##[[ ! -f "$R2" ]] ‚Üí valida que el par R2 exista; si no, lo salta con aviso.
##Comando cutadapt en una sola l√≠nea ‚Üí evita que zsh interprete l√≠neas sueltas como comandos (-a, -A, etc.).
##"${base:t}" ‚Üí en zsh, :t es el basename (quita ruta), por si ejecutas desde otra carpeta.
##Mensaje final con la ruta de resultados.
##El comando de Cutadapt se emple√≥ para el recorte de adaptadores y la depuraci√≥n de lecturas pareadas en formato FASTQ. Se ejecut√≥ con 8 hilos en paralelo (-j 8) especificando las secuencias de adaptadores para las lecturas forward y reverse (-a y -A), as√≠ como la eliminaci√≥n de colas poli-A de al menos diez nucle√≥tidos. Se aplic√≥ un filtrado de calidad en ambos extremos de las lecturas (-q 20,20), estableciendo una longitud m√≠nima de 20 pb (-m 20), con un m√°ximo de 0 nucle√≥tidos ambiguos permitidos (--max-n 0). Para la detecci√≥n de adaptadores, se defini√≥ un solapamiento m√≠nimo de 5 pb (--overlap 5) y una tasa m√°xima de error de 0.1 (-e 0.1). Se activ√≥ adem√°s la opci√≥n de recortar nucle√≥tidos ambiguos en los extremos (--trim-n) y de descartar un par si alguna de las lecturas no cumpl√≠a los criterios (--pair-filter=any). Los resultados se almacenaron en archivos FASTQ recortados para cada par de lecturas, junto con un reporte resumido en formato JSON que describe las estad√≠sticas del proceso.


##¬†Despu√©s del recorte de secuencias con Cutadapt, las lecturas obtenidas fueron evaluadas en t√©rminos de calidad mediante un flujo automatizado en zsh. El procedimiento consisti√≥ en localizar los archivos recortados en la carpeta cutadapt_results, sobre los cuales se ejecut√≥ FastQC para generar reportes individuales con m√©tricas como calidad por base, contenido GC, duplicaci√≥n y longitudes de lectura. Posteriormente, los resultados de FastQC se integraron mediante MultiQC, obteni√©ndose un reporte consolidado en formato HTML y archivos tabulares que permiten la comparaci√≥n global de todas las muestras en un solo documento.

#!/bin/zsh

set -e
# Sale inmediatamente si alg√∫n comando falla (evita resultados a medias)

setopt NULL_GLOB
# En zsh, hace que los patrones que no coinciden no queden literales (se expanden a vac√≠o)

outdir="cutadapt_results"
# Nombre de la carpeta donde quedaron los archivos recortados por cutadapt

[[ -d "$outdir" ]] || { echo "No existe la carpeta '$outdir'. Corre primero el recorte con cutadapt."; exit 1; }
# Verifica que exista la carpeta de resultados de cutadapt (si no, termina con mensaje claro)

cd "$outdir"
# Entra a la carpeta de resultados de cutadapt

typeset -a TRIMMED
TRIMMED=( *.trimmed.fastq *.trimmed.fastq.gz )
# Construye la lista de archivos recortados a evaluar con FastQC (acepta .fastq y .fastq.gz)

(( ${#TRIMMED} > 0 )) || { echo "No se encontraron archivos *.trimmed.fastq(.gz) en '$outdir'."; exit 1; }
# Si no hay archivos recortados, termina con mensaje claro

mkdir -p fastqc_results
# Crea una subcarpeta para almacenar los reportes de FastQC

fastqc -t 8 -o fastqc_results $TRIMMED
# Ejecuta FastQC con 8 hilos, guardando todos los reportes dentro de fastqc_results

cd fastqc_results
# Entra a la subcarpeta con los reportes de FastQC

multiqc . --outdir . --filename multiqc_trimmed_fastqc
# Ejecuta MultiQC sobre los outputs de FastQC en esta carpeta; genera multiqc_trimmed_fastqc.html y multiqc_data/

echo "An√°lisis completado. Revisa: $(pwd)/multiqc_trimmed_fastqc.html"
# Mensaje final con la ruta completa del reporte consolidado


## El procedimiento consisti√≥ en la integraci√≥n de los reportes de MultiQC obtenidos antes (raw) y despu√©s (trimmed) del recorte de secuencias. Para ello, los archivos multiqc_general_stats.txt fueron procesados de manera que cada muestra quedara normalizada, eliminando sufijos t√©cnicos como _001, _R1 o _R2. A cada registro se le a√±adi√≥ una columna denominada Tipo, que permiti√≥ distinguir entre datos crudos y recortados. Finalmente, ambos conjuntos se unificaron en un solo archivo tabular, lo que posibilita la comparaci√≥n directa de las m√©tricas de calidad de secuenciaci√≥n entre etapas del flujo de an√°lisis.

cd .. #volver a root

#!/bin/zsh

set -euo pipefail
# -e: salir si algo falla; -u: error si usas variables no definidas; -o pipefail: propaga errores en pipes

# ========= RUTAS DE ENTRADA ==========

# Archivo de MultiQC post-trimming (ya confirmado)
F_TRIM="cutadapt_results/fastqc_results/multiqc_trimmed_fastqc_data/multiqc_general_stats.txt"

# Buscar autom√°ticamente el multiqc_general_stats.txt de los datos crudos dentro de fastqc_raw
RAW_STATS=$(find fastqc_raw -maxdepth 5 -type f -name "multiqc_general_stats.txt" | head -n 1)

if [[ -z "$RAW_STATS" ]]; then
  echo "‚ùå No se encontr√≥ ning√∫n multiqc_general_stats.txt dentro de fastqc_raw"
  exit 1
fi

F_RAW="$RAW_STATS"

OUT="comparativo_general_stats.txt"

# Verificaci√≥n de existencia
[[ -f "$F_TRIM" ]] || { echo "No se encuentra: $F_TRIM"; exit 1; }
[[ -f "$F_RAW"  ]] || { echo "No se encuentra: $F_RAW";  exit 1; }

# ========= FUNCI√ìN PARA PROCESAR CADA ARCHIVO ==========

process_file() {
  local file=$1
  local tipo=$2
  awk -v TIPO="$tipo" -F'\t' 'NR==1 {
      # Encabezado: solo se imprime una vez
      if (!printed++) {
        printf "Sample\tTipo"
        for (i=2;i<=NF;i++) printf "\t%s", $i
        printf "\n"
      }
      next
    }
    {
      # Normaliza nombre de muestra
      sample=$1
      sub(/_001$/, "", sample)
      sub(/_R[12]$/, "", sample)
      printf "%s\t%s", sample, TIPO
      for (i=2;i<=NF;i++) printf "\t%s", $i
      printf "\n"
    }' "$file"
}

# ========= EJECUCI√ìN ==========

echo "Usando archivo trimmed: $F_TRIM"
echo "Usando archivo raw:     $F_RAW"

process_file "$F_TRIM" "trimmed" > "$OUT"
process_file "$F_RAW"  "raw"     >> "$OUT"

echo "‚úÖ Archivo unificado generado: $PWD/$OUT"


##Las lecturas filtradas fueron procesadas con SortMeRNA para la identificaci√≥n y eliminaci√≥n de secuencias de ARN ribosomal (rRNA). El an√°lisis se realiz√≥ utilizando las bases de datos de referencia provistas por la herramienta (SILVA y Rfam), clasificando las lecturas en dos conjuntos: rRNA y no rRNA. Las lecturas no ribosomales se conservaron para los an√°lisis posteriores de expresi√≥n y anotaci√≥n funcional, con el fin de reducir la sobre-representaci√≥n de rRNA en las bibliotecas y mejorar la calidad de la informaci√≥n transcript√≥mica.

##Trimmed reads were processed with SortMeRNA to identify and remove ribosomal RNA (rRNA) sequences. The analysis was performed using the reference databases provided by the software (SILVA and Rfam), classifying reads into two groups: rRNA and non-rRNA. Non-ribosomal reads were retained for downstream expression and functional annotation analyses, in order to reduce rRNA overrepresentation in the libraries and improve transcriptomic data quality.


#El siguiente paso se realiza en un ambiente instalado en conda llamado bio. Revisa instalaci√≥n de sortmeRNA, regista version (4.3.7)

conda activate bio

sortmerna --version 

#Las bases de referencia de sortMeRNA deben estar disponibles, en esta caso "/Users/bio2/sortmerna_db"


#!/bin/zsh

set -e
setopt NULL_GLOB

# ============================
# CONFIGURACI√ìN (EDITA SOLO RUTAS DE FASTQ SI CAMBIAN)
# ============================

# FASTQ recortados por cutadapt
IN_DIR="cutadapt_results"

# Carpeta de salida
OUT_ROOT="sortmerna_results"

# Hilos de CPU
THREADS=12

# === Rutas ACTUALIZADAS para las bases ===

DB_DIR="/Users/bio2/sortmerna_db/rRNA_databases"
IDX_DIR="/Users/bio2/sortmerna_db/index"

mkdir -p "$IDX_DIR"

REF_ARGS=(
  --ref "$DB_DIR/silva-bac-16s-id90.fasta"
  --ref "$DB_DIR/silva-arc-16s-id95.fasta"
  --ref "$DB_DIR/silva-euk-18s-id95.fasta"
  --ref "$DB_DIR/silva-bac-23s-id98.fasta"
)

# Crear carpetas si no existen
mkdir -p "$OUT_ROOT" "$IDX_DIR"

# ============================
# BUSCAR FASTQ
# ============================

R1_LIST=( "$IN_DIR"/*_R1.trimmed.fastq(.N) "$IN_DIR"/*_R1.trimmed.fastq.gz(.N) )

if (( ${#R1_LIST} == 0 )); then
  echo "‚ùå No se encontraron archivos R1 en $IN_DIR"
  exit 1
fi

# ============================
# PROCESAR CADA MUESTRA
# ============================

for R1 in "${R1_LIST[@]}"; do

  if [[ "$R1" == *.gz ]]; then
    base="${R1%_R1.trimmed.fastq.gz}"
    R2="${base}_R2.trimmed.fastq.gz"
  else
    base="${R1%_R1.trimmed.fastq}"
    R2="${base}_R2.trimmed.fastq"
  fi

  sample="${base##*/}"
  OUT_DIR="$OUT_ROOT/$sample"
  mkdir -p "$OUT_DIR"

  if [[ ! -f "$R2" ]]; then
    echo "‚ö†Ô∏è No se encontr√≥ el archivo R2 para $R1 (esperado: $R2)"
    continue
  fi

  echo "‚ñ∂Ô∏è Procesando muestra: $sample"
  echo "   R1: $R1"
  echo "   R2: $R2"
  echo "   Salida: $OUT_DIR"

  ALIGNED_BASE="$OUT_DIR/${sample}.rRNA"
  OTHER_BASE="$OUT_DIR/${sample}.non_rRNA"
  LOGFILE="$OUT_DIR/${sample}.sortmerna.log"

 sortmerna \
  "${REF_ARGS[@]}" \
  --reads "$R1" \
  --reads "$R2" \
  --paired_in \
  --fastx \
  --aligned "$ALIGNED_BASE" \
  --other   "$OTHER_BASE" \
  --workdir "$OUT_DIR" \
  --idx-dir "$IDX_DIR" \
  --threads "$THREADS" \
  &> "$LOGFILE"


  echo "   ‚úî Finalizado: $sample"
  echo "     Archivos rRNA:     ${ALIGNED_BASE}*"
  echo "     Archivos no-rRNA:  ${OTHER_BASE}*"
  echo "     Log:                $LOGFILE"

done

echo "üéâ Proceso completo. Resultados en $OUT_ROOT"

#An√°lisis taxon√≥mico con MetaPhlAn. MetaPhlAn se utiliza para determinar la composici√≥n taxon√≥mica de la comunidad microbiana presente en las muestras metatranscript√≥micas. Este an√°lisis se basa en la detecci√≥n de genes marcadores clado-espec√≠ficos, lo que permite identificar organismos desde nivel filo hasta nivel especie con alta precisi√≥n. En este pipeline, MetaPhlAn se ejecuta usando lecturas limpias post-Cutadapt y no la salida filtrada por SortMeRNA. La raz√≥n es que MetaPhlAn no depende de genes ribosomales ni requiere remover rRNA: su algoritmo utiliza marcadores √∫nicos distribuidos en los genomas microbianos, por lo que necesita todas las lecturas para maximizar la detecci√≥n de los microorganismos presentes. De esta forma, el perfil taxon√≥mico refleja mejor la composici√≥n real de la comunidad activa.

#Activar y revisar instalaci√≥n en otro ambiente (version 4.2.4)

conda activate meta4
metaphlan --version


#!/bin/zsh

set -e
setopt NULL_GLOB

# ============================
# CONFIGURACI√ìN
# ============================

# Carpeta con FASTQ post-Cutadapt
IN_DIR="cutadapt_results"

# Carpeta de salida
OUT_DIR="metaphlan_results"
mkdir -p "$OUT_DIR"

# N√∫mero de hilos
THREADS=12

# ============================
# BUSCAR ARCHIVOS R1
# ============================

R1_LIST=( "$IN_DIR"/*_R1.trimmed.fastq(.N) "$IN_DIR"/*_R1.trimmed.fastq.gz(.N) )

if (( ${#R1_LIST} == 0 )); then
  echo "‚ùå No se encontraron archivos R1 en $IN_DIR"
  exit 1
fi

# ============================
# PROCESAR CADA MUESTRA
# ============================

for R1 in "${R1_LIST[@]}"; do
  
  # identificar R2
  if [[ "$R1" == *.gz ]]; then
    base="${R1%_R1.trimmed.fastq.gz}"
    R2="${base}_R2.trimmed.fastq.gz"
  else
    base="${R1%_R1.trimmed.fastq}"
    R2="${base}_R2.trimmed.fastq"
  fi

  sample="${base##*/}"
  OUT="$OUT_DIR/${sample}.profile.txt"

  echo "‚ñ∂Ô∏è  MetaPhlAn: procesando $sample"

 metaphlan "$R1","$R2" \
  --input_type fastq \
  --nproc "$THREADS" \
  --mapout "${OUT%.txt}.bowtie2.bz2" \
  -o "$OUT"

  echo "   ‚úî Finalizado: $OUT"

done

echo "üéâ MetaPhlAn completado para todas las muestras."



### Subt√≠tulo nivel 2

Contenido
